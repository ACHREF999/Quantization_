# Quantization_
This Image explains it well (Quantization Aware Training ):  
where we make the optimization process tries to take considertaion into the quantization effect on the input and params
![Quantization Overview](https://miro.medium.com/v2/resize:fit:1400/1*xB-umnC2Mlu4YFy-DkFjCA.png)


Going to lower precision usually means taking float32 into int8 , either symmetrically or asymmetrically : 
![Float to Int Quantization]([https://miro.medium.com/v2/resize:fit:1400/1*xB-umnC2Mlu4YFy-DkFjCA.png](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8ffa0c54-88bf-45c1-8636-bdb097bb8e6b_1172x848.png))
